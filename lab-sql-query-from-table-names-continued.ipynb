{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d930c89-4954-4e39-be5a-601c1dd89512",
   "metadata": {
    "id": "7d930c89-4954-4e39-be5a-601c1dd89512"
   },
   "source": [
    "# SQL query from table names - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a03f026a",
   "metadata": {
    "id": "a03f026a"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a05b80-88fd-42b2-ba89-763074ae74e9",
   "metadata": {
    "id": "53a05b80-88fd-42b2-ba89-763074ae74e9"
   },
   "source": [
    "## The old Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "922f8d24",
   "metadata": {
    "id": "922f8d24"
   },
   "outputs": [],
   "source": [
    "#The old prompt\n",
    "old_context = [ {'role':'system', 'content':\"\"\"\n",
    "you are a bot to assist in create SQL commands, all your answers should start with \\\n",
    "this is your SQL, and after that an SQL that can do what the user request. \\\n",
    "Your Database is composed by a SQL database with some tables. \\\n",
    "Try to maintain the SQL order simple.\n",
    "Put the SQL command in white letters with a black background, and just after \\\n",
    "a simple and concise text explaining how it works.\n",
    "If the user ask for something that can not be solved with an SQL Order \\\n",
    "just answer something nice and simple, maximum 10 words, asking him for something that \\\n",
    "can be solved with SQL.\n",
    "\"\"\"} ]\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "first table:\n",
    "{\n",
    "  \"tableName\": \"employees\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"tipo\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"nombre\": \"name\",\n",
    "      \"tipo\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "second table:\n",
    "{\n",
    "  \"tableName\": \"salary\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"year\",\n",
    "      \"type\": \"date\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"salary\",\n",
    "      \"type\": \"float\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "third table:\n",
    "{\n",
    "  \"tablename\": \"studies\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"ID\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"educational_level\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Institution\",\n",
    "      \"type\": \"varchar\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Years\",\n",
    "      \"type\": \"date\"\n",
    "    }\n",
    "    {\n",
    "      \"name\": \"Speciality\",\n",
    "      \"type\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377acaae-7dd0-4d13-bc68-9e33741c231c",
   "metadata": {
    "id": "377acaae-7dd0-4d13-bc68-9e33741c231c"
   },
   "source": [
    "## New Prompt.\n",
    "We are going to improve it following the instructions of a Paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853). I recommend you read that paper.\n",
    "\n",
    "For each table, we will define the structure using the same syntax as in a SQL create table command, and add the sample rows of the content.\n",
    "\n",
    "Finally, at the end of the prompt, we'll include some example queries with the SQL that the model should generate. This technique is called Few-Shot Samples, in which we provide the prompt with some examples to assist it in generating the correct SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5334f942",
   "metadata": {
    "id": "5334f942"
   },
   "outputs": [],
   "source": [
    "context = [ {'role':'system', 'content':\"\"\"\n",
    " CREATE SEVERAL (3+) TABLES HERE\n",
    "\"\"\"} ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993",
   "metadata": {
    "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993"
   },
   "outputs": [],
   "source": [
    "#FEW SHOT SAMPLES\n",
    "context.append( {'role':'system', 'content':\"\"\"\n",
    " -- Maintain the SQL order simple and efficient as you can, using valid SQL Lite, answer the following questions for the table provided above.\n",
    "WRITE IN YOUR CONTEXT QUERIES HERE\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b90f417a",
   "metadata": {
    "id": "b90f417a"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c",
   "metadata": {
    "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c"
   },
   "source": [
    "## NL2SQL Samples\n",
    "We're going to review some examples generated with the old prompt and others with the new prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59e8202c-ce34-487e-9037-c65a263423ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59e8202c-ce34-487e-9037-c65a263423ed",
    "outputId": "f7a97b9f-45d7-4f78-8979-a796c5bc42fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT e.name\n",
      "FROM employees e\n",
      "JOIN salary s ON e.ID_Usr = s.ID_Usr\n",
      "ORDER BY s.salary DESC\n",
      "LIMIT 1;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"\"\"YOUR QUERY HERE\"\"\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
    "outputId": "029844da-5f1f-4f65-9adb-4d9c1cafacea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT e.name\n",
      "FROM employees e\n",
      "JOIN salary s ON e.ID_usr = s.ID_usr\n",
      "ORDER BY s.salary DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "This SQL query retrieves the name of the employee who is best paid by joining the \"employees\" table with the \"salary\" table on the ID_usr field. It then orders the result by salary in descending order and limits the output to only one row, which corresponds to the employee with the highest salary.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"YOUR QUERY HERE\", old_context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
    "outputId": "2934cdec-bea0-44db-b047-33e70dcf8ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT st.Institution, AVG(sa.salary) AS avg_salary\n",
      "FROM studies st\n",
      "JOIN employees e ON st.ID_Usr = e.ID_Usr\n",
      "JOIN salary sa ON e.ID_Usr = sa.ID_Usr\n",
      "GROUP BY st.Institution\n",
      "ORDER BY avg_salary DESC\n",
      "LIMIT 1;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "print(return_CCRMSQL(\"YOUR QUERY HERE\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
    "outputId": "605724a1-0d89-4ed9-d8ec-1aeeae6dc287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT s.Institution\n",
      "FROM studies s\n",
      "JOIN salary sa ON s.ID_usr = sa.ID_usr\n",
      "GROUP BY s.Institution\n",
      "ORDER BY AVG(sa.salary) DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "This SQL query joins the \"studies\" and \"salary\" tables on the ID_usr column. It then calculates the average salary for each institution, orders the results in descending order based on the average salary, and returns the institution with the highest average salary.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "print(return_CCRMSQL(\"YOUR QUERY HERE\", old_context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47",
   "metadata": {
    "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong.\n",
    "     - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27efbab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== New Context Test ===\n",
      "```sql\n",
      "SELECT client_name\n",
      "FROM clients\n",
      "WHERE industry = 'Tech';\n",
      "```\n",
      "\n",
      "This SQL query selects the `client_name` from the `clients` table where the `industry` is 'Tech'. It retrieves a list of clients in the Tech industry.\n",
      "\n",
      "=== Old Context Test ===\n",
      "```sql\n",
      "SELECT *\n",
      "FROM salary\n",
      "WHERE year = '2023';\n",
      "```\n",
      "\n",
      "This SQL query selects all columns from the `salary` table where the year is equal to 2023, showing only the salaries for the year 2023.\n",
      "\n",
      "=== Edge Case Test ===\n",
      "I'm here to help with SQL queries. If you have any questions related to databases or data manipulation, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# --- Old Context Setup ---\n",
    "old_context = [{\n",
    "    'role': 'system',\n",
    "    'content': \"\"\"\n",
    "    You are a SQL assistant. Respond with SQL code first (markdown format) followed by a brief explanation.\n",
    "    Available tables:\n",
    "    1. employees (ID_usr[int], name[varchar])\n",
    "    2. salary (ID_usr[int], year[date], salary[float])\n",
    "    3. studies (ID[int], ID_usr[int], educational_level[int], Institution[varchar], Years[date], Speciality[varchar])\n",
    "    \"\"\"\n",
    "}]\n",
    "\n",
    "# --- New Context Setup ---\n",
    "new_context = [{\n",
    "    'role': 'system',\n",
    "    'content': \"\"\"\n",
    "    You are a SQL assistant. Respond with SQL code first (markdown format) followed by a brief explanation.\n",
    "    Available tables:\n",
    "    1. departments (department_id[int], name[varchar], manager_id[int])\n",
    "    2. projects (project_id[int], project_name[varchar], start_date[date], end_date[date], budget[float])\n",
    "    3. clients (client_id[int], client_name[varchar], industry[varchar], contact_email[varchar])\n",
    "    \"\"\"\n",
    "}]\n",
    "\n",
    "# Add few-shot examples to new context\n",
    "new_context.append({\n",
    "    'role': 'system',\n",
    "    'content': \"\"\"\n",
    "    Example 1: List Sales department employees\n",
    "    ```sql\n",
    "    SELECT employees.name \n",
    "    FROM employees \n",
    "    JOIN departments ON employees.department_id = departments.department_id \n",
    "    WHERE departments.name = 'Sales';\n",
    "    ```\n",
    "    \n",
    "    Example 2: 2023 projects total budget\n",
    "    ```sql\n",
    "    SELECT SUM(budget) AS total_budget \n",
    "    FROM projects \n",
    "    WHERE start_date >= '2023-01-01';\n",
    "    ```\n",
    "    \"\"\"\n",
    "})\n",
    "\n",
    "def generate_sql(user_query, context):\n",
    "    \"\"\"Generate SQL using OpenAI's API\"\"\"\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    messages = context.copy()\n",
    "    messages.append({'role': 'user', 'content': user_query})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# --- Test Cases ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with new context\n",
    "    print(\"=== New Context Test ===\")\n",
    "    print(generate_sql(\"List clients in Tech industry\", new_context))\n",
    "    \n",
    "    # Test with old context\n",
    "    print(\"\\n=== Old Context Test ===\")\n",
    "    print(generate_sql(\"Show salaries from 2023\", old_context))\n",
    "    \n",
    "    # Edge case test\n",
    "    print(\"\\n=== Edge Case Test ===\")\n",
    "    print(generate_sql(\"How's the weather tomorrow?\", new_context))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac81577",
   "metadata": {},
   "source": [
    "**One-Page Report**\n",
    "Summary of Findings\n",
    "Effective Variations:\n",
    "\n",
    "The minimalist prompt (Variation 1) reliably produced clean SQL.\n",
    "\n",
    "Commented SQL (Variation 3) worked well and added clarity.\n",
    "\n",
    "Hallucination Issues:\n",
    "\n",
    "When forced to use JOINs (Variation 2), the model invented a department_id field in projects, which didn’t exist. This highlights risks in overly restrictive prompts.\n",
    "\n",
    "Context Dependency:\n",
    "\n",
    "The new context performed better for queries about clients/projects but failed on salary-related questions (missing tables).\n",
    "\n",
    "Lessons Learned\n",
    "Specificity Matters: Clear table definitions and constraints reduce hallucinations.\n",
    "\n",
    "Balanced Instructions: Over-constraining prompts (e.g., forcing JOINs) can backfire.\n",
    "\n",
    "Adaptability: The model adapts to provided examples, making few-shot samples critical for guiding output.\n",
    "\n",
    "Recommendations\n",
    "Use minimalist prompts for simplicity.\n",
    "\n",
    "Validate table/field existence in prompts to avoid hallucinations.\n",
    "\n",
    "Include 2–3 few-shot examples to set query patterns.\n",
    "\n",
    "Conclusion: GPT-3.5 performs robustly when context and prompts are well-structured. Hallucinations occur with ambiguous instructions, emphasizing the need for precise schema definitions and balanced guidance."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
